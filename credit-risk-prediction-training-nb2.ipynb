{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b561e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:13:32.311992Z",
     "iopub.status.busy": "2024-05-16T07:13:32.311655Z",
     "iopub.status.idle": "2024-05-16T07:13:37.566012Z",
     "shell.execute_reply": "2024-05-16T07:13:37.565252Z"
    },
    "papermill": {
     "duration": 5.262036,
     "end_time": "2024-05-16T07:13:37.568435",
     "exception": false,
     "start_time": "2024-05-16T07:13:32.306399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import lightgbm as lgb  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "import polars as pl  # type: ignore\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool  # type: ignore\n",
    "from glob import glob\n",
    "from IPython.display import display  # type: ignore\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin  # type: ignore\n",
    "from sklearn.metrics import roc_auc_score  # type: ignore\n",
    "from sklearn.model_selection import StratifiedGroupKFold  # type: ignore\n",
    "from typing import Any\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n",
    "TRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c58353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:13:37.577148Z",
     "iopub.status.busy": "2024-05-16T07:13:37.576837Z",
     "iopub.status.idle": "2024-05-16T07:13:37.610230Z",
     "shell.execute_reply": "2024-05-16T07:13:37.609494Z"
    },
    "papermill": {
     "duration": 0.039676,
     "end_time": "2024-05-16T07:13:37.611973",
     "exception": false,
     "start_time": "2024-05-16T07:13:37.572297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Utility:\n",
    "    @staticmethod\n",
    "    def get_feat_defs(ending_with: str) -> None:\n",
    "        \"\"\"\n",
    "        Retrieves feature definitions from a CSV file based on the specified ending.\n",
    "\n",
    "        Args:\n",
    "        - ending_with (str): Ending to filter feature definitions.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Filtered feature definitions.\n",
    "        \"\"\"\n",
    "        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n",
    "\n",
    "        filtered_feats: pl.DataFrame = feat_defs.filter(\n",
    "            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n",
    "        )\n",
    "\n",
    "        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n",
    "            print(filtered_feats)\n",
    "\n",
    "        filtered_feats = None\n",
    "        feat_defs = None\n",
    "\n",
    "    @staticmethod\n",
    "    def find_index(lst: list[Any], item: Any) -> int | None:\n",
    "        \"\"\"\n",
    "        Finds the index of an item in a list.\n",
    "\n",
    "        Args:\n",
    "        - lst (list): List to search.\n",
    "        - item (Any): Item to find in the list.\n",
    "\n",
    "        Returns:\n",
    "        - int | None: Index of the item if found, otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return lst.index(item)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def dtype_to_str(dtype: pl.DataType) -> str:\n",
    "        \"\"\"\n",
    "        Converts Polars data type to string representation.\n",
    "\n",
    "        Args:\n",
    "        - dtype (pl.DataType): Polars data type.\n",
    "\n",
    "        Returns:\n",
    "        - str: String representation of the data type.\n",
    "        \"\"\"\n",
    "        dtype_map = {\n",
    "            pl.Decimal: \"Decimal\",\n",
    "            pl.Float32: \"Float32\",\n",
    "            pl.Float64: \"Float64\",\n",
    "            pl.UInt8: \"UInt8\",\n",
    "            pl.UInt16: \"UInt16\",\n",
    "            pl.UInt32: \"UInt32\",\n",
    "            pl.UInt64: \"UInt64\",\n",
    "            pl.Int8: \"Int8\",\n",
    "            pl.Int16: \"Int16\",\n",
    "            pl.Int32: \"Int32\",\n",
    "            pl.Int64: \"Int64\",\n",
    "            pl.Date: \"Date\",\n",
    "            pl.Datetime: \"Datetime\",\n",
    "            pl.Duration: \"Duration\",\n",
    "            pl.Time: \"Time\",\n",
    "            pl.Array: \"Array\",\n",
    "            pl.List: \"List\",\n",
    "            pl.Struct: \"Struct\",\n",
    "            pl.String: \"String\",\n",
    "            pl.Categorical: \"Categorical\",\n",
    "            pl.Enum: \"Enum\",\n",
    "            pl.Utf8: \"Utf8\",\n",
    "            pl.Binary: \"Binary\",\n",
    "            pl.Boolean: \"Boolean\",\n",
    "            pl.Null: \"Null\",\n",
    "            pl.Object: \"Object\",\n",
    "            pl.Unknown: \"Unknown\",\n",
    "        }\n",
    "\n",
    "        return dtype_map.get(dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Finds occurrences of features ending with a specific string in Parquet files.\n",
    "\n",
    "        Args:\n",
    "        - regex_path (str): Regular expression to match Parquet file paths.\n",
    "        - ending_with (str): Ending to filter feature names.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n",
    "        \"\"\"\n",
    "        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n",
    "            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n",
    "        )\n",
    "        feat_defs.sort(by=[\"Variable\"])\n",
    "\n",
    "        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n",
    "        feats.sort()\n",
    "\n",
    "        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n",
    "\n",
    "        for path in glob(str(regex_path)):\n",
    "            df_schema: dict = pl.read_parquet_schema(path)\n",
    "\n",
    "            for feat, dtype in df_schema.items():\n",
    "                index: int = Utility.find_index(feats, feat)\n",
    "                if index != None:\n",
    "                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n",
    "                    occurrences[index][1].add(Path(path).stem)\n",
    "\n",
    "        data_types: list[str] = [None] * feat_defs.height\n",
    "        file_locs: list[str] = [None] * feat_defs.height\n",
    "\n",
    "        for i, feat in enumerate(feats):\n",
    "            data_types[i] = list(occurrences[i][0])\n",
    "            file_locs[i] = list(occurrences[i][1])\n",
    "\n",
    "        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n",
    "        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n",
    "\n",
    "        return feat_defs\n",
    "\n",
    "    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Reduces memory usage of a DataFrame by converting column types.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): DataFrame to optimize.\n",
    "        - name (str): Name of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Optimized DataFrame.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        int_types = [\n",
    "            pl.Int8,\n",
    "            pl.Int16,\n",
    "            pl.Int32,\n",
    "            pl.Int64,\n",
    "            pl.UInt8,\n",
    "            pl.UInt16,\n",
    "            pl.UInt32,\n",
    "            pl.UInt64,\n",
    "        ]\n",
    "        float_types = [pl.Float32, pl.Float64]\n",
    "\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            if col_type in int_types + float_types:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if c_min is not None and c_max is not None:\n",
    "                    if col_type in int_types:\n",
    "                        if c_min >= 0:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.uint8).min\n",
    "                                and c_max <= np.iinfo(np.uint8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint16).min\n",
    "                                and c_max <= np.iinfo(np.uint16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint32).min\n",
    "                                and c_max <= np.iinfo(np.uint32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint64).min\n",
    "                                and c_max <= np.iinfo(np.uint64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt64))\n",
    "                        else:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.int8).min\n",
    "                                and c_max <= np.iinfo(np.int8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int16).min\n",
    "                                and c_max <= np.iinfo(np.int16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int32).min\n",
    "                                and c_max <= np.iinfo(np.int32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int64).min\n",
    "                                and c_max <= np.iinfo(np.int64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int64))\n",
    "                    elif col_type in float_types:\n",
    "                        if (\n",
    "                            c_min > np.finfo(np.float32).min\n",
    "                            and c_max < np.finfo(np.float32).max\n",
    "                        ):\n",
    "                            df = df.with_columns(df[col].cast(pl.Float32))\n",
    "\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n",
    "        \"\"\"\n",
    "        Converts a Polars DataFrame to a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): Polars DataFrame to convert.\n",
    "        - cat_cols (list[str]): List of categorical columns. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n",
    "        \"\"\"\n",
    "        df: pd.DataFrame = df.to_pandas()\n",
    "\n",
    "        if cat_cols is None:\n",
    "            cat_cols = list(df.select_dtypes(\"object\").columns)\n",
    "\n",
    "        df[cat_cols] = df[cat_cols].astype(\"str\")\n",
    "\n",
    "        return df, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb1f0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:13:37.619205Z",
     "iopub.status.busy": "2024-05-16T07:13:37.618930Z",
     "iopub.status.idle": "2024-05-16T07:13:37.622772Z",
     "shell.execute_reply": "2024-05-16T07:13:37.621994Z"
    },
    "papermill": {
     "duration": 0.009476,
     "end_time": "2024-05-16T07:13:37.624597",
     "exception": false,
     "start_time": "2024-05-16T07:13:37.615121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"P\")\n",
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"M\")\n",
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"A\")\n",
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"D\")\n",
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"T\")\n",
    "# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"L\")\n",
    "# feat_defs:pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n",
    "# with pl.Config(fmt_str_lengths=1000, tbl_rows=-1, tbl_width_chars=180):\n",
    "#     print(feat_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea7dfc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:13:37.631701Z",
     "iopub.status.busy": "2024-05-16T07:13:37.631434Z",
     "iopub.status.idle": "2024-05-16T07:14:05.794053Z",
     "shell.execute_reply": "2024-05-16T07:14:05.792936Z"
    },
    "papermill": {
     "duration": 28.168764,
     "end_time": "2024-05-16T07:14:05.796445",
     "exception": false,
     "start_time": "2024-05-16T07:13:37.627681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pl.read_parquet('/kaggle/input/credit-risk-prediction-train-data/train_final.parquet')\n",
    "df_train=df_train[[col for col in df_train.columns if 'crb' not in col.split('_')]]\n",
    "df_train, cat_cols = Utility.to_pandas(df_train)\n",
    "pd.Series(cat_cols).to_csv('cat_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dae5bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:14:05.804970Z",
     "iopub.status.busy": "2024-05-16T07:14:05.804442Z",
     "iopub.status.idle": "2024-05-16T07:14:05.812689Z",
     "shell.execute_reply": "2024-05-16T07:14:05.811784Z"
    },
    "papermill": {
     "duration": 0.014565,
     "end_time": "2024-05-16T07:14:05.814785",
     "exception": false,
     "start_time": "2024-05-16T07:14:05.800220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A voting ensemble model that combines predictions from multiple estimators.\n",
    "\n",
    "    Parameters:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Attributes:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Methods:\n",
    "    - fit(X, y=None): Fit the model to the training data.\n",
    "    - predict(X): Predict class labels for samples.\n",
    "    - predict_proba(X): Predict class probabilities for samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators: list[BaseEstimator]):\n",
    "        \"\"\"\n",
    "        Initialize the VotingModel with a list of base estimators.\n",
    "\n",
    "        Args:\n",
    "        - estimators (list): List of base estimators.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "        - y: Target labels (ignored).\n",
    "\n",
    "        Returns:\n",
    "        - self: Returns the instance itself.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class labels.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class probabilities.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a499c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:14:05.822333Z",
     "iopub.status.busy": "2024-05-16T07:14:05.822010Z",
     "iopub.status.idle": "2024-05-16T07:14:05.825875Z",
     "shell.execute_reply": "2024-05-16T07:14:05.825082Z"
    },
    "papermill": {
     "duration": 0.009815,
     "end_time": "2024-05-16T07:14:05.827755",
     "exception": false,
     "start_time": "2024-05-16T07:14:05.817940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb0c363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:14:05.835647Z",
     "iopub.status.busy": "2024-05-16T07:14:05.835347Z",
     "iopub.status.idle": "2024-05-16T11:04:56.258258Z",
     "shell.execute_reply": "2024-05-16T11:04:56.257367Z"
    },
    "papermill": {
     "duration": 13850.439316,
     "end_time": "2024-05-16T11:04:56.270412",
     "exception": false,
     "start_time": "2024-05-16T07:14:05.831096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.836999\n",
      "[200]\tvalid_0's auc: 0.84448\n",
      "[300]\tvalid_0's auc: 0.846995\n",
      "[400]\tvalid_0's auc: 0.847646\n",
      "[500]\tvalid_0's auc: 0.847964\n",
      "[600]\tvalid_0's auc: 0.848101\n",
      "[700]\tvalid_0's auc: 0.848268\n",
      "[800]\tvalid_0's auc: 0.848352\n",
      "[900]\tvalid_0's auc: 0.848362\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid_0's auc: 0.848405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830702\n",
      "[200]\tvalid_0's auc: 0.841106\n",
      "[300]\tvalid_0's auc: 0.845245\n",
      "[400]\tvalid_0's auc: 0.847368\n",
      "[500]\tvalid_0's auc: 0.848494\n",
      "[600]\tvalid_0's auc: 0.849139\n",
      "[700]\tvalid_0's auc: 0.849661\n",
      "[800]\tvalid_0's auc: 0.849961\n",
      "[900]\tvalid_0's auc: 0.850073\n",
      "[1000]\tvalid_0's auc: 0.850295\n",
      "[1100]\tvalid_0's auc: 0.850536\n",
      "[1200]\tvalid_0's auc: 0.850635\n",
      "[1300]\tvalid_0's auc: 0.850696\n",
      "Early stopping, best iteration is:\n",
      "[1289]\tvalid_0's auc: 0.850742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.840908\n",
      "[200]\tvalid_0's auc: 0.848891\n",
      "[300]\tvalid_0's auc: 0.851706\n",
      "[400]\tvalid_0's auc: 0.852594\n",
      "[500]\tvalid_0's auc: 0.852914\n",
      "[600]\tvalid_0's auc: 0.852823\n",
      "[700]\tvalid_0's auc: 0.853038\n",
      "[800]\tvalid_0's auc: 0.853119\n",
      "[900]\tvalid_0's auc: 0.85318\n",
      "[1000]\tvalid_0's auc: 0.853294\n",
      "[1100]\tvalid_0's auc: 0.853197\n",
      "Early stopping, best iteration is:\n",
      "[1018]\tvalid_0's auc: 0.853311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.83443\n",
      "[200]\tvalid_0's auc: 0.845548\n",
      "[300]\tvalid_0's auc: 0.849471\n",
      "[400]\tvalid_0's auc: 0.851647\n",
      "[500]\tvalid_0's auc: 0.852935\n",
      "[600]\tvalid_0's auc: 0.853621\n",
      "[700]\tvalid_0's auc: 0.854075\n",
      "[800]\tvalid_0's auc: 0.854288\n",
      "[900]\tvalid_0's auc: 0.854526\n",
      "[1000]\tvalid_0's auc: 0.854716\n",
      "[1100]\tvalid_0's auc: 0.85495\n",
      "[1200]\tvalid_0's auc: 0.854991\n",
      "Early stopping, best iteration is:\n",
      "[1113]\tvalid_0's auc: 0.855006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.836448\n",
      "[200]\tvalid_0's auc: 0.844695\n",
      "[300]\tvalid_0's auc: 0.847285\n",
      "[400]\tvalid_0's auc: 0.848345\n",
      "[500]\tvalid_0's auc: 0.848706\n",
      "[600]\tvalid_0's auc: 0.848948\n",
      "[700]\tvalid_0's auc: 0.849187\n",
      "[800]\tvalid_0's auc: 0.849308\n",
      "[900]\tvalid_0's auc: 0.849418\n",
      "[1000]\tvalid_0's auc: 0.849439\n",
      "Early stopping, best iteration is:\n",
      "[960]\tvalid_0's auc: 0.849467\n",
      "\n",
      "CV AUC scores for CatBoost: [0.8474960103556818, 0.8474800658967352, 0.8526866661920671, 0.8522394895613856, 0.8472490072096683]\n",
      "Maximum CV AUC score for Catboost: 0.8526866661920671\n",
      "\n",
      "CV AUC scores for LGBM: [0.8484052749238885, 0.8507423426977616, 0.8533105127001114, 0.8550056802018898, 0.849466541364752]\n",
      "Maximum CV AUC score for LGBM: 0.8550056802018898\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop(columns=[\"target\", \"case_id\", \"week_num\"])\n",
    "y = df_train[\"target\"]\n",
    "pd.Series(X.columns).to_csv('feat.csv', index=False)\n",
    "weeks = df_train[\"week_num\"]\n",
    "\n",
    "del df_train\n",
    "gc.collect()\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "params1 = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"device\": device,\n",
    "    \"extra_trees\": True,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"l1_regularization\": 0.1,\n",
    "    \"l2_regularization\": 10,\n",
    "    \"max_depth\": 20,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 2000,\n",
    "    \"num_leaves\": 64,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"device\": device,\n",
    "    \"extra_trees\": True,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"l1_regularization\": 0.1,\n",
    "    \"l2_regularization\": 10,\n",
    "    \"max_depth\": 16,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 2000,\n",
    "    \"num_leaves\": 72,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "fitted_models_cat = []\n",
    "fitted_models_lgb = []\n",
    "\n",
    "cv_scores_cat = []\n",
    "cv_scores_lgb = []\n",
    "est_cnt=6000\n",
    "iter_cnt = 0\n",
    "for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n",
    "    val_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        best_model_min_trees = 1200,\n",
    "        boosting_type = \"Plain\",\n",
    "        eval_metric = \"AUC\",\n",
    "        iterations = est_cnt,\n",
    "        learning_rate = 0.05,\n",
    "        l2_leaf_reg = 10,\n",
    "        max_leaves = 64,\n",
    "        random_seed = 42,\n",
    "        task_type = \"GPU\",\n",
    "        use_best_model = True\n",
    "    )\n",
    "\n",
    "    clf.fit(train_pool, eval_set=val_pool, verbose=False)\n",
    "    fitted_models_cat.append(clf)\n",
    "\n",
    "    y_pred_valid = clf.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_cat.append(auc_score)\n",
    "\n",
    "    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n",
    "\n",
    "    if iter_cnt % 2 == 0:\n",
    "        model = lgb.LGBMClassifier(**params1)\n",
    "    else:\n",
    "        model = lgb.LGBMClassifier(**params2)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)],\n",
    "    )\n",
    "    fitted_models_lgb.append(model)\n",
    "\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_lgb.append(auc_score)\n",
    "\n",
    "    iter_cnt += 1\n",
    "\n",
    "model = VotingModel(fitted_models_cat + fitted_models_lgb)\n",
    "\n",
    "print(f\"\\nCV AUC scores for CatBoost: {cv_scores_cat}\")\n",
    "print(f\"Maximum CV AUC score for Catboost: {max(cv_scores_cat)}\", end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"CV AUC scores for LGBM: {cv_scores_lgb}\")\n",
    "print(f\"Maximum CV AUC score for LGBM: {max(cv_scores_lgb)}\", end=\"\\n\\n\")\n",
    "\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d85986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T11:04:56.291943Z",
     "iopub.status.busy": "2024-05-16T11:04:56.291639Z",
     "iopub.status.idle": "2024-05-16T11:05:03.029818Z",
     "shell.execute_reply": "2024-05-16T11:05:03.028925Z"
    },
    "papermill": {
     "duration": 6.751335,
     "end_time": "2024-05-16T11:05:03.031869",
     "exception": false,
     "start_time": "2024-05-16T11:04:56.280534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "datasetId": 5018384,
     "sourceId": 8427693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13894.505061,
   "end_time": "2024-05-16T11:05:04.089143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T07:13:29.584082",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
